{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"digit_recognition_keras.ipynb","version":"0.3.2","provenance":[{"file_id":"1L7P1nr9DVWqY45WTvRnw61Gg2OOd8WYx","timestamp":1558093597124},{"file_id":"1hegdVQsJKUwrfthHUj6FwfF8vs2eEh5I","timestamp":1558093040071}],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"w8ufwSBTEHM0","colab_type":"text"},"source":["# HAND WRITTEN DIGIT RECOGNIZER\n","\n","#### Have you ever wondered how we can classify an image with numbers 0-9 using deep learning. If yes, then you are about to find out how and implement the solution by yourselves. It is primarily image classification problem.\n","\n","\n","Post your doubt/feedback/discussion in our FB group unit [here](https://www.facebook.com/groups/colearninglounge/) in the appropriate section.\n","\n","## Table of content:\n","\n","*   Introduction to Deep Learning\n","*   Why Deep Learning now?\n","*   Introduction to CNN\n","*   How to approach a Image Classification Problem.\n","*   Problem Statement\n","*   Implementation/Demo\n","\n","###  Introduction to Deep Learning\n","\n","Just like we use our human brains to identify patterns and classify various types of information, deep learning algorithms can be taught to accomplish the same tasks for machines. \n","\n","Example: \n","\n","Automatic car driving system is a good example of deep learning. Deep Learning has many applications like smart vision, speech recognition and natural language processing \n","\n","\n","### Why Deep Learning?\n","\n","Deep learning exits from 1970 but it became popular in the last 5 years due to the following reasons. \n","\n","* More availability of data and less cost of storage devices \n","\n","* More computational power availability and more optimized algorithm which takes less power and utilizes less resources. \n","\n","Because of this deep learning has created a boom in computer vision. \n","\n","\n","### Introduction to CNN\n","\n","Convolutional Neural Networks are a part of Deep learning which are mostly used for computer vision problem. They are called Convolutional Neural networks because most of the layers in the network involves Convolution operation. The whole CNN started with a Perceptron model.  \n","\n","#### Perceptron model\n","Perceptron model is inspired from human neuron. The idea of perceptron is that it outputs 1 if the equated sum of inputs and weights are greater than or equal to threshold. It outputs 0 if the equated sum is less than threshold. Perceptron model has some limitations. Example: XOR function is not linearly separable so we cannot use perceptron to predict truth table of XOR. The output of perceptron is always binary. So, researchers have taught that network of perceptron model solves these issues and they came up with an architecture called multi-layer perceptron architecture called neural network. If the neural network contains more of convolution operation, then it is called Convolutional Neural Networks. \n","\n","CNN contains many layers. Some of the important layers are listed below.  \n","\n","* Convolution operation extracts the features of the image like vertical edges, horizontal edges etc. Pooling Operation reduces the size of the input while preserving the important features of the image.  \n","\n","* Pooling operation does down sampling. There are two types of pooling.  \n","\n","* Maxpooling : Takes the max of given kernel size  \n","\n","* AvgPooling: Takes the average of given kernel size. \n","\n","* Fullyconnected layer: this layer is called fully connected since each input is connected to every neuron in hidden layer. \n","\n","### How to approach a Image Classification Problem\n","\n","* First, we need a dataset to train our model. We can prepare our dataset, or we have some opensource datasets. Some of the opensource datasets are ImageNet, MNIST, VisualQA etc  \n","\n","* Next we need to have a loss function and optimizer. Loss function calculates the loss of our model and optimizer optimizes this loss in such a way that our model learns its weights faster. Some loss functions: MSE, Catogorical loss entropySome Optimizors: SGD, Adam \n","\n","* Then we need a visual algorithm like LENET, Googlenet etc for classifying the imagesAnd  \n","\n","* we needed test dataset to test our model. \n","\n","* Then we need to choose any of the popular frameworks in Python for deep learning like caffe, caffe2, pytorch, tenssorflow and keras etc to implement it. \n","\n","We choose Keras to implement Digit Recognizer since it is very user friendly and good for deep learning beginners So, we will start our hello world (digit recognition using keras) program of deep learning using Keras. \n","\n","## Problem Statement\n","\n","We need to predict the labels for the images of digits(0-9) using deep learning with the help of Keras framework. \n","\n","## Implementation\n"]},{"cell_type":"markdown","metadata":{"id":"D4YibXKMp2uE","colab_type":"text"},"source":["## Installing Dependencies\n","First of all we need to install all the dependencies for our demo. The below packages are need for running our demo."]},{"cell_type":"code","metadata":{"id":"3o8Q1m7zhlj_","colab_type":"code","colab":{}},"source":["!pip install numpy==1.15.0\n","!pip install pandas==0.22.0\n","!pip install matplotlib==2.2.2\n","!pip install scikit-learn==0.15.0\n","!pip install keras\n","!pip install tensorflow==1.7.0"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c1mFuaTHqZFe","colab_type":"text"},"source":["## Importing necessary packages\n","As in every python/any language we need to import the necessary libraries.The above modules are necessary for our demo"]},{"cell_type":"code","metadata":{"id":"RXI-Avu6fTG8","colab_type":"code","outputId":"53dd99fb-2b75-4173-cb55-9030c1536ebf","executionInfo":{"status":"ok","timestamp":1561909267375,"user_tz":-330,"elapsed":1938,"user":{"displayName":"G.DURGA RAO VENKY","photoUrl":"https://lh5.googleusercontent.com/-2g0Acg4jV54/AAAAAAAAAAI/AAAAAAAAA5k/PcKKflFzC_E/s64/photo.jpg","userId":"04293114280532425490"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","import numpy as np\n","np.random.seed(1337)\n","from matplotlib import pyplot as plt\n","from keras.models import Sequential,model_from_json\n","import keras\n","from sklearn.cross_validation import train_test_split\n","from keras.utils import np_utils"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"KD5pxzvXqf3j","colab_type":"text"},"source":["## Preprocessing Dataset\n","Any machine learning or deep learning program start with dataset preparation. Dataset preparation involves cleansing the data, labeling the data, splitting the dataset into train and test  etc. Fortunately  we dont need to prepare the dataset since we are using open source dataset  [MNIST](http://yann.lecun.com/exdb/mnist/) dataset which contains images of 0-9 and these are also labelled for us to use. So we divide the dataset into two parts train and test. train dataset has 60000 images and test dataset has 10000 images. In keras we have a module called mnist through which we download the dataset and then load and split the data using \"**mnist.load_data()**\"\"."]},{"cell_type":"code","metadata":{"id":"fQO2cd7VpfSV","colab_type":"code","colab":{}},"source":["def load_from_mnist(self):\n","    mnist=keras.datasets.mnist\n","    (x_train, x_train_label),(x_test, x_test_label) = mnist.load_data()\n","    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n","    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n","    return x_test,x_test_label,x_train,x_train_label"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4l8N9DjrsZGf","colab_type":"text"},"source":["## Create Model/Network\n","The next step in Deep learning is to decide on the network/model/deep learning algorthm to use. Since we need to detect what is the number in the image we will be using [LENET ](http://yann.lecun.com/exdb/lenet/)architecture which is light weight and takes less computational power. So, we need to construct the Lenet algorithm using keras layers. Here we are using a sequential model which means it will be executing it in a sequential way. We will start adding layer by layer using \"add\" function. Here we are using 3 unique layers. Convolution, MaxPool and fullyconnected layer(Dense layer). We use flatten to convert a 2D or 3D dimensional tensor into 1D tensor. \n"]},{"cell_type":"code","metadata":{"id":"eF_6_dGusVcB","colab_type":"code","colab":{}},"source":["def gen_model(self):\n","    self.model.add(keras.layers.Conv2D(filters=6, kernel_size=5, strides=(1, 1), padding=\"same\", input_shape=(28, 28, 1),\n","                                  data_format=\"channels_last\", activation=\"relu\"))\n","    self.model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    self.model.add(keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), padding=\"valid\", activation=\"relu\"))\n","    self.model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","    self.model.add(keras.layers.Flatten())\n","    self.model.add(keras.layers.Dense(120, input_shape=(400,), activation='relu'))\n","    self.model.add(keras.layers.Dense(84, input_shape=(120,), activation='relu'))\n","    self.model.add(keras.layers.Dense(units=10, activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w_5ewtw5teLA","colab_type":"text"},"source":["## Encoding Labels\n","Next step is to encode the labels of test and train data. We will encode the labels since computer can understand only binary data but the mnist dataset contains output lables as 0-9 decimals. We encode the label as \"1\" as \"0 1 0 0 0 0 0 0 0 0\" ans 2 as \"0 0 1 0 0 0 0 0 0 0\" this encoding can be done by keras utils library.\"np_util.to_categorical\" convert decimal into the conversion whch we discussed before."]},{"cell_type":"code","metadata":{"id":"nKv4luXjtdFA","colab_type":"code","colab":{}},"source":["def encode_data(self):\n","    self.x_train_label = np_utils.to_categorical(self.x_train_label, self.no_of_classes)\n","    self.x_test_label = np_utils.to_categorical(self.x_test_label, self.no_of_classes)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"of2YD3W6vC95","colab_type":"text"},"source":["## Train the model\n","\n","So, its time for training our model. For training a model we need two things. One loss function and other optimizer. Loss function will try to calculate difference between observed and actual. Optimizer will try to optimize the loss function in a way it learns the weights faster. So, for this demo we choose \"categorical_crossentropy\" as loss function and optimizer as \"adam\". You can experiment with loss and optimizer to check which fits best for your algorithm. First we need to attach the loss and optimizer to our model and then using fit function we train our model using keras \"fit\" function which we use to train our model by passing the train data and its encoded labels. Here you can see two more arguments \"epoch\" and \"batch_size\". Here epoch means how many times you want to repeat your train data. For each epoch our model learns more and more about our data. You may under the assumption that if more epoch = more accurary thats true partially because there will be a saturation point after a certain epoch your model accurary doesn't change. So, epoch should be choosen wisely. Batchsize is how many input dataset items to train parallely. So, the advantage your computational power decreases and model can learn better parallely. Batch size has a limitation on the computational power. If you put more batchsize your machine may say out of memory.\n"]},{"cell_type":"code","metadata":{"id":"dU8oy-IzvBns","colab_type":"code","colab":{}},"source":["def train_model(self):\n","    self.model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n","#    self.model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])load_from_mnist\n","    self.model.fit(self.x_train, self.x_train_label, epochs=self.no_of_epochs, batch_size=self.batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYJVhrZJzmh8","colab_type":"text"},"source":["## Prediction Time\n","\n","So its time for inference. predict_output will do the inference on the test dataset and provide us with accuracy and loss numbers. So, keras model has a function predict which will predict based on the training. We pass test dataset of 10000 data points and a batch size. The output of the function is a 10000*10 tensor, we use argmax(axis=1) function to get max index value of 1x10 tensor. "]},{"cell_type":"code","metadata":{"id":"VcDnLQKPzlXM","colab_type":"code","colab":{}},"source":["def predict_output(self):\n","    # loss_and_metrics = model.evaluate(x_test, x_test_label,batch_size=32)\n","    classes = self.model.predict(self.x_test, batch_size=self.batch_size)\n","    classes = classes.argmax(axis=1)\n","    for row in range(0, 3):\n","        plt.title(\"label=%s\" % classes[row])\n","        plt.imshow(np.reshape(self.x_test[row], (28, 28)), cmap='gray')\n","        plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JWoTAWVz5-_7","colab_type":"text"},"source":["## Save Model\n","\n","We don't need to train our model everytime we wanted to test or make predictions. We can save our model once we train our model. So, we store our model in json format. We need to save our weights as well."]},{"cell_type":"code","metadata":{"id":"WiVqZgxo595b","colab_type":"code","colab":{}},"source":["def save_model(self):\n","    model_json = self.model.to_json()\n","    with open(\"%s.json\" % self.save_model_name, \"w\") as json_file:\n","        json_file.write(model_json)\n","    # serialize weights to HDF5\n","    self.model.save_weights(\"%s.h5\" % self.save_model_name)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oVQhmKeR9j0S","colab_type":"text"},"source":["## Using Pretrained Model\n","\n","Inorder to use our pretrained model and weights we need to load our model. We use \"load_weights\" to load the pretrained weights."]},{"cell_type":"code","metadata":{"id":"pZ1rLiA29i0P","colab_type":"code","colab":{}},"source":["def load_model(self):\n","    print(\"Loading model from disk\")\n","    # load json and create model\n","    json_file = open('%s.json' % self.save_model_name, 'r')\n","    loaded_model_json = json_file.read()\n","    json_file.close()\n","    self.model = model_from_json(loaded_model_json)\n","    # load weights into new model\n","    self.model.load_weights(\"%s.h5\" % self.save_model_name)\n","    print(\"Loaded model from disk\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TyAsJw_1AKSN","colab_type":"text"},"source":["## Main class to link all methods\n","We define a class called \"digit_recognition\" where we link all our functions and initialize our model parameters."]},{"cell_type":"code","metadata":{"id":"T_Fb9KeuADgx","colab_type":"code","colab":{}},"source":["class digit_recognition:\n","    def __init__(self):\n","        self.model=Sequential()\n","#        self.x_test,self.x_test_label,self.x_train,self.x_train_label=self.load_split_data()\n","        self.x_test, self.x_test_label, self.x_train, self.x_train_label = self.load_from_mnist() #load data from mnist\n","        self.no_of_epochs=5\n","        self.batch_size=300\n","        self.save_model_name='lenet'\n","        self.no_of_classes=10\n","#    load_split_data=load_split_data\n","    encode_data=encode_data\n","    gen_model=gen_model\n","    train_model=train_model\n","    predict_output=predict_output\n","    save_model=save_model\n","    load_model=load_model\n","    load_from_mnist=load_from_mnist"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SEjYyXVHBnmg","colab_type":"text"},"source":["## Methods to Run our Digit Recognizer\n","\n","Here we define two functions \"digit_recog_crt\" and \"digit_recog_reuse\". we use \"digit_recog_crt\" function to train and test and \"digit_recog_reuse\" function to reuse the trained model and load the model to test or predict."]},{"cell_type":"code","metadata":{"id":"St37cbMhBmuS","colab_type":"code","colab":{}},"source":["def digit_recog_crt():\n","    digit=digit_recognition()\n","    digit.encode_data()\n","    digit.gen_model()\n","    digit.train_model()\n","    digit.predict_output()\n","    digit.save_model()\n","\n","def digit_recog_reuse():\n","    digit = digit_recognition()\n","    digit.encode_data()\n","    digit.load_model()\n","    digit.predict_output()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rRHJ4oheJ1z8","colab_type":"text"},"source":["## Running Our Digit Recognizer"]},{"cell_type":"code","metadata":{"id":"FAMfTbE4jbV-","colab_type":"code","outputId":"2f46ba5f-f600-4d62-9aeb-d23109dbf54a","executionInfo":{"status":"ok","timestamp":1561112002306,"user_tz":-330,"elapsed":215333,"user":{"displayName":"G.DURGA RAO VENKY","photoUrl":"https://lh5.googleusercontent.com/-2g0Acg4jV54/AAAAAAAAAAI/AAAAAAAAA5k/PcKKflFzC_E/s64/photo.jpg","userId":"04293114280532425490"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["if __name__ == '__main__':\n","    digit_recog_crt()\n","#    digit_recog_reuse()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n","Epoch 1/5\n","60000/60000 [==============================] - 38s 634us/step - loss: 1.4108 - acc: 0.7851\n","Epoch 2/5\n","60000/60000 [==============================] - 37s 620us/step - loss: 0.1459 - acc: 0.9548\n","Epoch 3/5\n","60000/60000 [==============================] - 38s 632us/step - loss: 0.0915 - acc: 0.9717\n","Epoch 4/5\n","19200/60000 [========>.....................] - ETA: 26s - loss: 0.0671 - acc: 0.9793"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pt9hiucx_kUf","colab_type":"text"},"source":["# Future scope:\n","\n","*   We can use other networks like zfnet, alexnet and try experimenting with accuracy.\n","*   We can also extend it to recognize digits using our camera.\n","\n","\n","> This tutorial is intended to be a public resource. As such, if you see any glaring inaccuracies or if a critical topic is missing, please feel free to point it out or (preferably) submit a pull request to improve the tutorial. Also, we are always looking to improve the scope of this article. For anything feel free to mail us @ colearninglounge@gmail.com\n","\n","\n","> Author of this article is Venkata Durga Rao Gambali. You can follow him on [LinkedIn](https://www.linkedin.com/in/venkata-durga-rao-gambali-24606b79/), [GitHub](https://github.com/venkatadj).\n","\n","\n","\n","\n"]}]}