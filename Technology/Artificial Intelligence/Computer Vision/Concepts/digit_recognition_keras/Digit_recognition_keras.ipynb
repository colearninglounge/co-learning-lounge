{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_recognition_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o8Q1m7zhlj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install numpy==1.15.0\n",
        "!pip install pandas==0.22.0\n",
        "!pip install matplotlib==2.2.2\n",
        "!pip install scikit-learn==0.15.0\n",
        "!pip install keras\n",
        "!pip install tensorflow==1.7.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4YibXKMp2uE",
        "colab_type": "text"
      },
      "source": [
        "First of all we need to install all the dependencies for our demo. The above packages are need for running our demo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXI-Avu6fTG8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53dd99fb-2b75-4173-cb55-9030c1536ebf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(1337)\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.models import Sequential,model_from_json\n",
        "import keras\n",
        "from sklearn.cross_validation import train_test_split\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1mFuaTHqZFe",
        "colab_type": "text"
      },
      "source": [
        "As in every python/any language we need to import the necessary libraries.The above modules are necessary for our demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQO2cd7VpfSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_from_mnist(self):\n",
        "    mnist=keras.datasets.mnist\n",
        "    (x_train, x_train_label),(x_test, x_test_label) = mnist.load_data()\n",
        "    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "    return x_test,x_test_label,x_train,x_train_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD5pxzvXqf3j",
        "colab_type": "text"
      },
      "source": [
        "Any machine learning or deep learning program start with dataset preparation. Dataset preparation involves cleansing the data, labeling the data, splitting the dataset into train and test  etc. Fortunately  we dont need to prepare the dataset since we are using open source dataset  [MNIST](http://yann.lecun.com/exdb/mnist/) dataset which contains images of 0-9 and these are also labelled for us to use. So we divide the dataset into two parts train and test. train dataset has 60000 images and test dataset has 10000 images. In keras we have a module called mnist through which we load and split the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF_6_dGusVcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gen_model(self):\n",
        "    self.model.add(keras.layers.Conv2D(filters=6, kernel_size=5, strides=(1, 1), padding=\"same\", input_shape=(28, 28, 1),\n",
        "                                  data_format=\"channels_last\", activation=\"relu\"))\n",
        "    self.model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    self.model.add(keras.layers.Conv2D(filters=16, kernel_size=5, strides=(1, 1), padding=\"valid\", activation=\"relu\"))\n",
        "    self.model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    self.model.add(keras.layers.Flatten())\n",
        "    self.model.add(keras.layers.Dense(120, input_shape=(400,), activation='relu'))\n",
        "    self.model.add(keras.layers.Dense(84, input_shape=(120,), activation='relu'))\n",
        "    self.model.add(keras.layers.Dense(units=10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l8N9DjrsZGf",
        "colab_type": "text"
      },
      "source": [
        "The next step in Deep learning is to decide on the network/model/deep learning algorthm to use. Since we need to detect what is the number in the image we will be using [LENET ](http://yann.lecun.com/exdb/lenet/)architecture which is light weight and takes less computational power. So, we need to construct the Lenet algorithm using keras layers. Here we are using a sequential model which means it will be executing it in a sequential way. We will start adding layer by layer using \"add\" function. Here we are using 3 unique layers. Convolution, MaxPool and fullyconnected layer(Dense layer). We use flatten to convert a 2D or 3D dimensional tensor into 1D tensor. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKv4luXjtdFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_data(self):\n",
        "    self.x_train_label = np_utils.to_categorical(self.x_train_label, self.no_of_classes)\n",
        "    self.x_test_label = np_utils.to_categorical(self.x_test_label, self.no_of_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_5ewtw5teLA",
        "colab_type": "text"
      },
      "source": [
        "Next step is to encode the labels of test and train data. We will encode the labels since computer can understand only binary data but the mnist dataset contains output lables as 0-9 decimals. We encode the label as \"1\" as \"0 1 0 0 0 0 0 0 0 0\" ans 2 as \"0 0 1 0 0 0 0 0 0 0\" this encoding can be done by keras utils library.\"np_util.to_categorical\" convert decimal into the conversion whch we discussed before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dU8oy-IzvBns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(self):\n",
        "    self.model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "#    self.model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])load_from_mnist\n",
        "    self.model.fit(self.x_train, self.x_train_label, epochs=self.no_of_epochs, batch_size=self.batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "of2YD3W6vC95",
        "colab_type": "text"
      },
      "source": [
        "So, its time for training our model. For training a model we need two things. One loss function and other optimizer. Loss function will try to calculate difference between observed and actual. Optimizer will try to optimize the loss function in a way it learns the weights faster. So, for this demo we choose \"categorical_crossentropy\" as loss function and optimizer as \"adam\". You can experiment with loss and optimizer to check which fits best for your algorithm. First we need to attach the loss and optimizer to our model and then using fit function we train our model using keras \"fit\" function which we use to train our model by passing the train data and its encoded labels. Here you can see two more arguments \"epoch\" and \"batch_size\". Here epoch means how many times you want to repeat your train data. For each epoch our model learns more and more about our data. You may under the assumption that if more epoch = more accurary thats true partially because there will be a saturation point after a certain epoch your model accurary doesn't change. So, epoch should be choosen wisely. Batchsize is how many input dataset items to train parallely. So, the advantage your computational power decreases and model can learn better parallely. Batch size has a limitation on the computational power. If you put more batchsize your machine may say out of memory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcDnLQKPzlXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_output(self):\n",
        "    # loss_and_metrics = model.evaluate(x_test, x_test_label,batch_size=32)\n",
        "    classes = self.model.predict(self.x_test, batch_size=self.batch_size)\n",
        "    classes = classes.argmax(axis=1)\n",
        "    for row in range(0, 3):\n",
        "        plt.title(\"label=%s\" % classes[row])\n",
        "        plt.imshow(np.reshape(self.x_test[row], (28, 28)), cmap='gray')\n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYJVhrZJzmh8",
        "colab_type": "text"
      },
      "source": [
        "So its time for inference. predict_output will do the inference on the test dataset and provide us with accuracy and loss numbers. So, keras model has a function predict which will predict based on the training. We pass test dataset of 10000 data points and a batch size. The output of the function is a 10000*10 tensor, we use argmax(axis=1) function to get max index value of 1x10 tensor. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiVqZgxo595b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(self):\n",
        "    model_json = self.model.to_json()\n",
        "    with open(\"%s.json\" % self.save_model_name, \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    self.model.save_weights(\"%s.h5\" % self.save_model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWoTAWVz5-_7",
        "colab_type": "text"
      },
      "source": [
        "We don't need to train our model everytime we wanted to test or make predictions. We can save our model once we train our model. So, we store our model in json format. We need to save our weights as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ1rLiA29i0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(self):\n",
        "    print(\"Loading model from disk\")\n",
        "    # load json and create model\n",
        "    json_file = open('%s.json' % self.save_model_name, 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "    self.model = model_from_json(loaded_model_json)\n",
        "    # load weights into new model\n",
        "    self.model.load_weights(\"%s.h5\" % self.save_model_name)\n",
        "    print(\"Loaded model from disk\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVQhmKeR9j0S",
        "colab_type": "text"
      },
      "source": [
        "Inorder to use our pretrained model and weights we need to load our model. We use \"load_weights\" to load the pretrained weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Fb9KeuADgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class digit_recognition:\n",
        "    def __init__(self):\n",
        "        self.model=Sequential()\n",
        "#        self.x_test,self.x_test_label,self.x_train,self.x_train_label=self.load_split_data()\n",
        "        self.x_test, self.x_test_label, self.x_train, self.x_train_label = self.load_from_mnist() #load data from mnist\n",
        "        self.no_of_epochs=5\n",
        "        self.batch_size=300\n",
        "        self.save_model_name='lenet'\n",
        "        self.no_of_classes=10\n",
        "#    load_split_data=load_split_data\n",
        "    encode_data=encode_data\n",
        "    gen_model=gen_model\n",
        "    train_model=train_model\n",
        "    predict_output=predict_output\n",
        "    save_model=save_model\n",
        "    load_model=load_model\n",
        "    load_from_mnist=load_from_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyAsJw_1AKSN",
        "colab_type": "text"
      },
      "source": [
        "We define a class called \"digit_recognition\" where we link all our functions and initialize our model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St37cbMhBmuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def digit_recog_crt():\n",
        "    digit=digit_recognition()\n",
        "    digit.encode_data()\n",
        "    digit.gen_model()\n",
        "    digit.train_model()\n",
        "    digit.predict_output()\n",
        "    digit.save_model()\n",
        "\n",
        "def digit_recog_reuse():\n",
        "    digit = digit_recognition()\n",
        "    digit.encode_data()\n",
        "    digit.load_model()\n",
        "    digit.predict_output()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEjYyXVHBnmg",
        "colab_type": "text"
      },
      "source": [
        "Here we define two functions \"digit_recog_crt\" and \"digit_recog_reuse\". we use \"digit_recog_crt\" function to train and test and \"digit_recog_reuse\" function to reuse the trained model and load the model to test or predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAMfTbE4jbV-",
        "colab_type": "code",
        "outputId": "2f46ba5f-f600-4d62-9aeb-d23109dbf54a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    digit_recog_crt()\n",
        "#    digit_recog_reuse()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 38s 634us/step - loss: 1.4108 - acc: 0.7851\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 37s 620us/step - loss: 0.1459 - acc: 0.9548\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 38s 632us/step - loss: 0.0915 - acc: 0.9717\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 38s 635us/step - loss: 0.0650 - acc: 0.9803\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 37s 622us/step - loss: 0.0510 - acc: 0.9840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkBThB5L6f2m27dH1DfSuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}